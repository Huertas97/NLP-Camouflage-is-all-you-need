{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "\n",
    "This notebook show the experiments for ideal MASK and BLANK filters. \n",
    "\n",
    "- First we load the data, \n",
    "- generate the camouflage saving the metadata (positions of tokens camouflaged)\n",
    "- then we apply the filters substituting the camouflaged tokens with the MASK or BLANK token and save to .spacy files.\n",
    "- Evalaute the model on the test filtered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.36.2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "\n",
    "# import before spacy to avoid conflicts with PyTorch GPU setup\n",
    "from thinc.api import set_gpu_allocator, require_gpu \n",
    "set_gpu_allocator(\"pytorch\")\n",
    "require_gpu(0)\n",
    "\n",
    "import spacy\n",
    "spacy.require_gpu()\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from pyleetspeak.pyleetspeak import modes, WordCamouflage_Augmenter, NER_data_generator\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "home = str(Path.home())\n",
    "\n",
    "# Create logger\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Create handlers\n",
    "c_handler = logging.StreamHandler(sys.stdout)\n",
    "c_handler.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "# Create custom formatter that sets the color of the log message based on its level\n",
    "class ColoredFormatter(logging.Formatter):\n",
    "    def format(self, record):\n",
    "        if record.levelno == logging.DEBUG:\n",
    "            color = \"\\x1b[34m\"  # blue\n",
    "        elif record.levelno == logging.INFO:\n",
    "            color = \"\\x1b[32m\"  # green\n",
    "        elif record.levelno == logging.WARNING:\n",
    "            color = \"\\x1b[33m\"  # yellow\n",
    "        else:\n",
    "            color = \"\\x1b[31m\"  # red\n",
    "        message = super().format(record)\n",
    "        message = color + message + \"\\x1b[0m\"  # reset color\n",
    "        return message\n",
    "\n",
    "\n",
    "# Create formatters and add them to handlers get line of code where the log was created\n",
    "c_format = ColoredFormatter(\"%(asctime)s - %(name)s - %(levelname)s - %(lineno)d - %(message)s \")\n",
    "f_format = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "c_handler.setFormatter(c_format)\n",
    "\n",
    "# Create logger and add handlers to it\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(c_handler)\n",
    "\n",
    "import transformers\n",
    "transformers.__version__ # '4.36.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 22 08:41:47 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.171.04             Driver Version: 535.171.04   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Quadro RTX 8000                Off | 00000000:37:00.0 Off |                  Off |\n",
      "| 60%   78C    P2             259W / 260W |  13213MiB / 49152MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro RTX 8000                Off | 00000000:86:00.0 Off |                  Off |\n",
      "| 33%   31C    P8               9W / 260W |      3MiB / 49152MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load OffenSemEval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# offen_10_leet_data_path = f\"{home}/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/25_per_advanced_20/test.spacy\"\n",
    "\n",
    "offen_10_leet_data_path = f\"{home}/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Ori_Data/dev.spacy\"\n",
    "\n",
    "\n",
    "# # from spacy to pandas\n",
    "# def spacy_to_pandas(spacy_data_path):\n",
    "#     docs = []\n",
    "#     with open(spacy_data_path, 'r') as file:\n",
    "#         for line in file:\n",
    "#             # continue\n",
    "\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "\n",
    "offen_10_leet_data_path = f\"{home}/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Ori_Data/dev.spacy\"\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Cargar los datos\n",
    "doc_bin = DocBin().from_disk(offen_10_leet_data_path)\n",
    "docs = list(doc_bin.get_docs(nlp.vocab))\n",
    "\n",
    "# Convertir a DataFrame \n",
    "#  doc.cats --> {'OFF': False, 'NOT': True}\n",
    "data = [{\n",
    "    'text': doc.text,\n",
    "    'test_label': next((label for label, is_true in doc.cats.items() if is_true), None)\n",
    "} for doc in docs]\n",
    "offen_10_leet_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>test_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@USER @USER No clue where you get those numbers. We are the only country in the world with mass shootings and staggering death tolls from gun violence. How anyone is against gun control defies logic.</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@USER @USER @USER @USER yes he is</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@USER You are a beautiful model &amp;amp; HWs were jealous of that. I agree that Kendall should stay how she is &amp;amp; not have all that phony plastic surgery like her sisters. I don't event recognize Khloe anymore. Kylie needs to stop w/fillers. She's pretty on her own &amp;amp; not overdue it</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@USER @USER When he's not imparting these gems Michael Moore is stuffing his face.</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>// Rean's Arcane Gale is broken. If he is gonna be able to use that from scratch in Sen IV ( because of his demon form) it's gonna be cool  using it in every battle!</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>@USER @USER What really pisses me off about Asians in California voting for more gun control is that many should know better especially Koreans in LA. They all knew someone who had their businesses destroyed during the riots. At least this salty boi hasn’t forgotten: URL</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>@USER @USER @USER He. Is. A. Sociopath.</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>@USER He drew the saw because the marker was in his left hand which is connected to his right brain which is connected to his left eye which saw the saw. His right eye which is connected to his left brain saw the hammer. #PSYC1101</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>@USER Does penn state produce criminals too?</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320</th>\n",
       "      <td>@USER @USER @USER Think about - Trumper supporters have to hide their support for Trump and/or take the life into their own hands if they go out w/Trump #MAGA hat on-it never was like this in the America I remember.  We could have our own political beliefs but still be civil &amp;amp; cordial! Upsetting</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1321 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                              text  \\\n",
       "0                                                                                                          @USER @USER No clue where you get those numbers. We are the only country in the world with mass shootings and staggering death tolls from gun violence. How anyone is against gun control defies logic.   \n",
       "1                                                                                                                                                                                                                                                                                @USER @USER @USER @USER yes he is   \n",
       "2                   @USER You are a beautiful model &amp; HWs were jealous of that. I agree that Kendall should stay how she is &amp; not have all that phony plastic surgery like her sisters. I don't event recognize Khloe anymore. Kylie needs to stop w/fillers. She's pretty on her own &amp; not overdue it   \n",
       "3                                                                                                                                                                                                                               @USER @USER When he's not imparting these gems Michael Moore is stuffing his face.   \n",
       "4                                                                                                                                            // Rean's Arcane Gale is broken. If he is gonna be able to use that from scratch in Sen IV ( because of his demon form) it's gonna be cool  using it in every battle!   \n",
       "...                                                                                                                                                                                                                                                                                                            ...   \n",
       "1316                               @USER @USER What really pisses me off about Asians in California voting for more gun control is that many should know better especially Koreans in LA. They all knew someone who had their businesses destroyed during the riots. At least this salty boi hasn’t forgotten: URL   \n",
       "1317                                                                                                                                                                                                                                                                       @USER @USER @USER He. Is. A. Sociopath.   \n",
       "1318                                                                        @USER He drew the saw because the marker was in his left hand which is connected to his right brain which is connected to his left eye which saw the saw. His right eye which is connected to his left brain saw the hammer. #PSYC1101   \n",
       "1319                                                                                                                                                                                                                                                                  @USER Does penn state produce criminals too?   \n",
       "1320  @USER @USER @USER Think about - Trumper supporters have to hide their support for Trump and/or take the life into their own hands if they go out w/Trump #MAGA hat on-it never was like this in the America I remember.  We could have our own political beliefs but still be civil &amp; cordial! Upsetting   \n",
       "\n",
       "     test_label  \n",
       "0           NOT  \n",
       "1           NOT  \n",
       "2           NOT  \n",
       "3           OFF  \n",
       "4           OFF  \n",
       "...         ...  \n",
       "1316        NOT  \n",
       "1317        OFF  \n",
       "1318        OFF  \n",
       "1319        NOT  \n",
       "1320        OFF  \n",
       "\n",
       "[1321 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offen_10_leet_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Camouflage test data saving the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from copy import deepcopy, copy\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from codetiming import Timer\n",
    "import re\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_docs(data_tuples, nlp, labels):\n",
    "    \"\"\"_summary_\n",
    "    \"\"\"\n",
    "    docs = []\n",
    "    for text, label in tqdm(nlp.pipe(data_tuples, as_tuples=True), total = len(data_tuples), desc = \"Making docs\"):\n",
    "        doc = nlp(text)\n",
    "\n",
    "        for l in labels:\n",
    "            # Hay que hacer todos los labels\n",
    "            doc.cats[l] = label == l   \n",
    "\n",
    "        # put them into a nice list\n",
    "        docs.append(doc)\n",
    "    \n",
    "    return docs\n",
    "\n",
    "def leet_data(text, generator):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        text (_type_): _description_\n",
    "        generator (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    NER_data, ori_data = generator.generate_data(\n",
    "            sentence=text\n",
    "            # important_kws = [r\"\\bpfizer\\b\", r\"control\\b\", r\"vacuna\\b\", r\"vaccines\\b\"],\n",
    "        )\n",
    "\n",
    "    leet_text, _ =  NER_data[0]\n",
    "    return leet_text\n",
    "\n",
    "\n",
    "# Create a function to save pandas dataframe to spacy binary file\n",
    "def pd_2_spacy(df_train, df_dev, df_test, train_output_path, dev_output_path, test_output_path, labels, lang=\"en\"):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        df_train (_type_): _description_\n",
    "        df_dev (_type_): _description_\n",
    "        df_test (_type_): _description_\n",
    "        train_output_path (_type_): _description_\n",
    "        dev_output_path (_type_): _description_\n",
    "        test_output_path (_type_): _description_\n",
    "        lang (str, optional): _description_. Defaults to \"en\".\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # Spact empty model\n",
    "    nlp = spacy.blank(\"en\")\n",
    "\n",
    "    if df_train is not None:\n",
    "        # tuple of tuples. Each nested tuple is (Tweet, Label)\n",
    "        train_data_tuples = tuple(df_train.iloc[:, [0,1]].itertuples(index=False, name=None))\n",
    "                \n",
    "        # Make spacy DocBin\n",
    "        train_docs = make_docs(train_data_tuples, nlp, labels)\n",
    "\n",
    "        # Make outpath directory with Pathlib\n",
    "        Path(train_output_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # save to binary file \n",
    "        train_doc_bin = DocBin(docs=train_docs)\n",
    "        train_doc_bin.to_disk(train_output_path)\n",
    "        print(f\"Processed Train {len(train_data_tuples)} documents: {train_output_path}\")        \n",
    "\n",
    "    if df_dev is not None:\n",
    "        dev_data_tuples = tuple(df_dev.iloc[:, [0,1]].itertuples(index=False, name=None))\n",
    "        dev_docs = make_docs(dev_data_tuples, nlp, labels)\n",
    "        Path(dev_output_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "        dev_doc_bin = DocBin(docs=dev_docs)\n",
    "        dev_doc_bin.to_disk(dev_output_path)\n",
    "        print(f\"Processed Dev {len(dev_data_tuples)} documents: {dev_output_path}\")\n",
    "\n",
    "    if df_test is not None:\n",
    "        test_data_tuples = tuple(df_test.iloc[:, [0,1]].itertuples(index=False, name=None))\n",
    "        test_docs = make_docs(test_data_tuples, nlp, labels)\n",
    "        Path(test_output_path).parent.mkdir(parents=True, exist_ok=True)   \n",
    "\n",
    "        test_doc_bin = DocBin(docs=test_docs)\n",
    "        test_doc_bin.to_disk(test_output_path)\n",
    "        print(f\"Processed Test {len(test_data_tuples)} documents: {test_output_path}\")   \n",
    "\n",
    "\n",
    "def leet_data_augmenter(text, augmenter):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        text (_type_): _description_\n",
    "        generator (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    leet_text, ori_data = augmenter.transform(\n",
    "            text\n",
    "        )\n",
    "    return (leet_text, ori_data)\n",
    "\n",
    "\n",
    "# function to create dataframes witrh a percentage leet tweets\n",
    "def create_leet_augmenter_df(df_ori, frac, augmenter, column_to_leet):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        df (_type_): _description_\n",
    "        frac (_type_): _description_\n",
    "        generator (_type_): _description_\n",
    "        column_to_leet (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # Create a copy of the original dataframe for saving the leeted version\n",
    "    df_leeted = copy(df_ori)\n",
    "    df_leeted[\"Camouflaged\"] = False\n",
    "    \n",
    "    # Extract fraction to leet\n",
    "    df_to_leet = df_leeted.sample(frac=frac, random_state=42)\n",
    "\n",
    "    # Leet the tweets\n",
    "    # Step 2: Apply the function and store results\n",
    "    # Apply the augmenter and store both outputs in a temporary column as a tuple\n",
    "    # df_to_leet[column_to_leet] = df_to_leet[column_to_leet].progress_apply(leet_data_augmenter,  augmenter=augmenter)\n",
    "    df_to_leet[\"temp\"] = df_to_leet[column_to_leet].progress_apply(leet_data_augmenter,  augmenter=augmenter)\n",
    "\n",
    "    # Step 3: Split the tuple into two different columns\n",
    "    df_to_leet['leet_text'] = df_to_leet['temp'].apply(lambda x: x[0])\n",
    "    df_to_leet['annotations'] = df_to_leet['temp'].apply(lambda x: x[1])\n",
    "\n",
    "    df_to_leet[\"Camouflaged\"] = True\n",
    "\n",
    "    # count nan values in df_train_offen_to_leet[\"tweet\"] column\n",
    "    print(f\"Nan values in '{column_to_leet}' column: \", df_to_leet[column_to_leet].isna().sum())\n",
    "\n",
    "    # Substitute the original rows by the leeted version\n",
    "    # cols = list(df_leeted.columns) \n",
    "    # df_leeted.loc[df_leeted.index.isin(df_to_leet.index), cols] = df_to_leet[cols]    \n",
    "    # Concatenate the augmented and non-augmented parts into one DataFrame\n",
    "    # First, prepare the non-augmented part to include new columns filled with NaNs or appropriate defaults\n",
    "    df_not_leeted = df_leeted.drop(df_to_leet.index)\n",
    "    for col in ['leet_text', 'annotations']:\n",
    "        df_not_leeted[col] = pd.NA\n",
    "\n",
    "    # Concatenate back together\n",
    "    df_leeted = pd.concat([df_not_leeted, df_to_leet])\n",
    "\n",
    "    display( df_leeted.groupby(\"Camouflaged\").count() ) \n",
    "    \n",
    "    return df_leeted\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to apply the filters uing the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the mask using annotations\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def extract_masking_indices(annotations):\n",
    "    # Extract all indices from the annotations for masking\n",
    "    indices = []\n",
    "    for ann in annotations.get(\"meta\", []):\n",
    "        if \"leet_idxs\" in ann:\n",
    "            indices.append((ann[\"leet_idxs\"][0], ann[\"leet_idxs\"][1]))\n",
    "    # Sort indices by start, reverse to start masking from the end\n",
    "    indices.sort(reverse=True, key=lambda x: x[0])\n",
    "    return indices\n",
    "\n",
    "def apply_masks(text, indices, mask='[MASK]'):\n",
    "    \"\"\"Apply multiple mask replacements based on provided indices.\"\"\"\n",
    "    for start, end in indices:\n",
    "        if start < len(text) and end <= len(text) and start < end:\n",
    "            text = text[:start] + mask + text[end:]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NOT</th>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OFF</th>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tweet\n",
       "test_label       \n",
       "NOT           620\n",
       "OFF           240"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Test Data and Label\n",
    "test_data_offen_path = Path(home).joinpath(\"work/WordCamouflage_Resiliance/code/tmp_data/Offen/testset-levela.tsv\")\n",
    "test_label_offen_path = Path(home).joinpath(\"work/WordCamouflage_Resiliance/code/tmp_data/Offen/labels-levela.csv\")\n",
    "\n",
    "df_test_data_offen = pd.read_csv( test_data_offen_path, sep = \"\\t\")\n",
    "df_test_label_offen = pd.read_csv( test_label_offen_path, sep = \",\", header=None, names=[\"id\", \"test_label\"])\n",
    "\n",
    "# Merge Test Data and Test Label\n",
    "df_test_offen = pd.merge(df_test_data_offen, df_test_label_offen, on=\"id\", how=\"outer\").drop(labels = [\"id\"], axis = 1)\n",
    "\n",
    "print(\"Test\")\n",
    "display(df_test_offen.groupby(\"test_label\").count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the camouflage data. As the filters are **ideal** (they properly discern camouflage tokens from non-camouflaged tokens) independently of the levels, we can use any arbitrary level to create the data.  We will use the level 1. But we create the two version regardin the ratios of number of words camouflaged (v1  15% and v2 = 65%). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Level X.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:00<00:00, 120.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nan values in 'tweet' column:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>test_label</th>\n",
       "      <th>leet_text</th>\n",
       "      <th>annotations</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Camouflaged</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>774</td>\n",
       "      <td>774</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet  test_label  leet_text  annotations  temp\n",
       "Camouflaged                                                 \n",
       "False          774         774          0            0     0\n",
       "True            86          86         86           86    86"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 860/860 [00:00<00:00, 50403.15it/s]\n",
      "Making docs: 100%|██████████| 860/860 [00:00<00:00, 1328.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Test 860 documents: /home/alvaro/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/Level_1.1/10_per/test_mask_filter.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 860/860 [00:00<00:00, 50955.68it/s]\n",
      "Making docs: 100%|██████████| 860/860 [00:00<00:00, 1315.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Test 860 documents: /home/alvaro/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/Level_1.1/10_per/test_out_filter.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 215/215 [00:01<00:00, 129.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nan values in 'tweet' column:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>test_label</th>\n",
       "      <th>leet_text</th>\n",
       "      <th>annotations</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Camouflaged</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>645</td>\n",
       "      <td>645</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet  test_label  leet_text  annotations  temp\n",
       "Camouflaged                                                 \n",
       "False          645         645          0            0     0\n",
       "True           215         215        215          215   215"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 860/860 [00:00<00:00, 44341.61it/s]\n",
      "Making docs: 100%|██████████| 860/860 [00:00<00:00, 1373.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Test 860 documents: /home/alvaro/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/Level_1.1/25_per/test_mask_filter.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 860/860 [00:00<00:00, 45020.11it/s]\n",
      "Making docs: 100%|██████████| 860/860 [00:00<00:00, 1365.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Test 860 documents: /home/alvaro/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/Level_1.1/25_per/test_out_filter.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 430/430 [00:03<00:00, 123.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nan values in 'tweet' column:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>test_label</th>\n",
       "      <th>leet_text</th>\n",
       "      <th>annotations</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Camouflaged</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>430</td>\n",
       "      <td>430</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>430</td>\n",
       "      <td>430</td>\n",
       "      <td>430</td>\n",
       "      <td>430</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet  test_label  leet_text  annotations  temp\n",
       "Camouflaged                                                 \n",
       "False          430         430          0            0     0\n",
       "True           430         430        430          430   430"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 860/860 [00:00<00:00, 37874.21it/s]\n",
      "Making docs: 100%|██████████| 860/860 [00:00<00:00, 1447.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Test 860 documents: /home/alvaro/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/Level_1.1/50_per/test_mask_filter.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 860/860 [00:00<00:00, 38218.11it/s]\n",
      "Making docs: 100%|██████████| 860/860 [00:00<00:00, 1457.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Test 860 documents: /home/alvaro/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/Level_1.1/50_per/test_out_filter.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 645/645 [00:05<00:00, 114.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nan values in 'tweet' column:  0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>test_label</th>\n",
       "      <th>leet_text</th>\n",
       "      <th>annotations</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Camouflaged</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>645</td>\n",
       "      <td>645</td>\n",
       "      <td>645</td>\n",
       "      <td>645</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet  test_label  leet_text  annotations  temp\n",
       "Camouflaged                                                 \n",
       "False          215         215          0            0     0\n",
       "True           645         645        645          645   645"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 860/860 [00:00<00:00, 27441.07it/s]\n",
      "Making docs: 100%|██████████| 860/860 [00:00<00:00, 1529.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Test 860 documents: /home/alvaro/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/Level_1.1/75_per/test_mask_filter.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 860/860 [00:00<00:00, 32882.41it/s]\n",
      "Making docs: 100%|██████████| 860/860 [00:00<00:00, 1533.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Test 860 documents: /home/alvaro/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/Level_1.1/75_per/test_out_filter.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 860/860 [00:06<00:00, 123.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nan values in 'tweet' column:  0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>test_label</th>\n",
       "      <th>leet_text</th>\n",
       "      <th>annotations</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Camouflaged</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>860</td>\n",
       "      <td>860</td>\n",
       "      <td>860</td>\n",
       "      <td>860</td>\n",
       "      <td>860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet  test_label  leet_text  annotations  temp\n",
       "Camouflaged                                                 \n",
       "True           860         860        860          860   860"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 860/860 [00:00<00:00, 27964.41it/s]\n",
      "Making docs: 100%|██████████| 860/860 [00:00<00:00, 1643.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Test 860 documents: /home/alvaro/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/Level_1.1/100_per/test_mask_filter.spacy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 860/860 [00:00<00:00, 29009.52it/s]\n",
      "Making docs: 100%|██████████| 860/860 [00:00<00:00, 1573.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Test 860 documents: /home/alvaro/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/Level_1.1/100_per/test_out_filter.spacy\n"
     ]
    }
   ],
   "source": [
    "# Create a test dataframe with 10% of leeted tweets wirth Level 1.1\n",
    "resiliance_level = \"Level_1.1\"\n",
    "resiliance_easy = [\"basic_leetspeak\"]\n",
    "augmenter = WordCamouflage_Augmenter.augmenter(\n",
    "    extractor_type=\"yake\",\n",
    "    max_top_n=5,\n",
    "    leet_punt_prb=0.9,\n",
    "    leet_change_prb=0.8,\n",
    "    leet_change_frq=0.8,\n",
    "    leet_uniform_change=0.5,\n",
    "    method=resiliance_easy,\n",
    "    return_kws=True,\n",
    ")\n",
    "\n",
    "#### 10% Leet ####\n",
    "df_test_offen_10_per_annot = create_leet_augmenter_df(\n",
    "    df_ori=df_test_offen, frac=0.1, augmenter=augmenter, column_to_leet=\"tweet\"\n",
    ")\n",
    "\n",
    "\n",
    "# Assuming df has the columns 'leet_text', 'annotations', and 'Camouflaged'\n",
    "df_test_offen_10_per_annot[\"leet_mask_filter\"] = (\n",
    "    df_test_offen_10_per_annot.progress_apply(\n",
    "        lambda row: (\n",
    "            apply_masks(row[\"leet_text\"], extract_masking_indices(row[\"annotations\"]))\n",
    "            if row[\"Camouflaged\"]\n",
    "            else row[\"tweet\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "pd_2_spacy(\n",
    "    df_train=None,\n",
    "    df_dev=None,\n",
    "    df_test=df_test_offen_10_per_annot.loc[:, [\"leet_mask_filter\", \"test_label\"]],\n",
    "    train_output_path=None,\n",
    "    dev_output_path=None,\n",
    "    test_output_path=f\"{home}/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/{resiliance_level}/10_per/test_mask_filter.spacy\",\n",
    "    lang=\"en\",\n",
    "    labels=df_test_offen_10_per_annot[\"test_label\"].to_list(),\n",
    ")\n",
    "\n",
    "\n",
    "df_test_offen_10_per_annot[\"leet_out_filter\"] = (\n",
    "    df_test_offen_10_per_annot.progress_apply(\n",
    "        lambda row: (\n",
    "            apply_masks(\n",
    "                row[\"leet_text\"], extract_masking_indices(row[\"annotations\"]), \"\"\n",
    "            )\n",
    "            if row[\"Camouflaged\"]\n",
    "            else row[\"tweet\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "pd_2_spacy(\n",
    "    df_train=None,\n",
    "    df_dev=None,\n",
    "    df_test=df_test_offen_10_per_annot.loc[:, [\"leet_out_filter\", \"test_label\"]],\n",
    "    train_output_path=None,\n",
    "    dev_output_path=None,\n",
    "    test_output_path=f\"{home}/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/{resiliance_level}/10_per/test_out_filter.spacy\",\n",
    "    lang=\"en\",\n",
    "    labels=df_test_offen_10_per_annot[\"test_label\"].to_list(),\n",
    ")\n",
    "\n",
    "\n",
    "#### 25% Leet ####\n",
    "df_test_offen_25_per_annot = create_leet_augmenter_df(\n",
    "    df_ori=df_test_offen, frac=0.25, augmenter=augmenter, column_to_leet=\"tweet\"\n",
    ")\n",
    "\n",
    "\n",
    "# Assuming df has the columns 'leet_text', 'annotations', and 'Camouflaged'\n",
    "df_test_offen_25_per_annot[\"leet_mask_filter\"] = (\n",
    "    df_test_offen_25_per_annot.progress_apply(\n",
    "        lambda row: (\n",
    "            apply_masks(row[\"leet_text\"], extract_masking_indices(row[\"annotations\"]))\n",
    "            if row[\"Camouflaged\"]\n",
    "            else row[\"tweet\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "pd_2_spacy(\n",
    "    df_train=None,\n",
    "    df_dev=None,\n",
    "    df_test=df_test_offen_25_per_annot.loc[:, [\"leet_mask_filter\", \"test_label\"]],\n",
    "    train_output_path=None,\n",
    "    dev_output_path=None,\n",
    "    test_output_path=f\"{home}/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/{resiliance_level}/25_per/test_mask_filter.spacy\",\n",
    "    lang=\"en\",\n",
    "    labels=df_test_offen_25_per_annot[\"test_label\"].to_list(),\n",
    ")\n",
    "\n",
    "\n",
    "df_test_offen_25_per_annot[\"leet_out_filter\"] = (\n",
    "    df_test_offen_25_per_annot.progress_apply(\n",
    "        lambda row: (\n",
    "            apply_masks(\n",
    "                row[\"leet_text\"], extract_masking_indices(row[\"annotations\"]), \"\"\n",
    "            )\n",
    "            if row[\"Camouflaged\"]\n",
    "            else row[\"tweet\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "pd_2_spacy(\n",
    "    df_train=None,\n",
    "    df_dev=None,\n",
    "    df_test=df_test_offen_25_per_annot.loc[:, [\"leet_out_filter\", \"test_label\"]],\n",
    "    train_output_path=None,\n",
    "    dev_output_path=None,\n",
    "    test_output_path=f\"{home}/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/{resiliance_level}/25_per/test_out_filter.spacy\",\n",
    "    lang=\"en\",\n",
    "    labels=df_test_offen_25_per_annot[\"test_label\"].to_list(),\n",
    ")\n",
    "\n",
    "\n",
    "#### 50% Leet ####\n",
    "df_test_offen_50_per_annot = create_leet_augmenter_df(\n",
    "    df_ori=df_test_offen, frac=0.50, augmenter=augmenter, column_to_leet=\"tweet\"\n",
    ")\n",
    "\n",
    "\n",
    "# Assuming df has the columns 'leet_text', 'annotations', and 'Camouflaged'\n",
    "df_test_offen_50_per_annot[\"leet_mask_filter\"] = (\n",
    "    df_test_offen_50_per_annot.progress_apply(\n",
    "        lambda row: (\n",
    "            apply_masks(row[\"leet_text\"], extract_masking_indices(row[\"annotations\"]))\n",
    "            if row[\"Camouflaged\"]\n",
    "            else row[\"tweet\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "pd_2_spacy(\n",
    "    df_train=None,\n",
    "    df_dev=None,\n",
    "    df_test=df_test_offen_50_per_annot.loc[:, [\"leet_mask_filter\", \"test_label\"]],\n",
    "    train_output_path=None,\n",
    "    dev_output_path=None,\n",
    "    test_output_path=f\"{home}/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/{resiliance_level}/50_per/test_mask_filter.spacy\",\n",
    "    lang=\"en\",\n",
    "    labels=df_test_offen_50_per_annot[\"test_label\"].to_list(),\n",
    ")\n",
    "\n",
    "\n",
    "df_test_offen_50_per_annot[\"leet_out_filter\"] = (\n",
    "    df_test_offen_50_per_annot.progress_apply(\n",
    "        lambda row: (\n",
    "            apply_masks(\n",
    "                row[\"leet_text\"], extract_masking_indices(row[\"annotations\"]), \"\"\n",
    "            )\n",
    "            if row[\"Camouflaged\"]\n",
    "            else row[\"tweet\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "pd_2_spacy(\n",
    "    df_train=None,\n",
    "    df_dev=None,\n",
    "    df_test=df_test_offen_50_per_annot.loc[:, [\"leet_out_filter\", \"test_label\"]],\n",
    "    train_output_path=None,\n",
    "    dev_output_path=None,\n",
    "    test_output_path=f\"{home}/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/{resiliance_level}/50_per/test_out_filter.spacy\",\n",
    "    lang=\"en\",\n",
    "    labels=df_test_offen_50_per_annot[\"test_label\"].to_list(),\n",
    ")\n",
    "\n",
    "\n",
    "#### 75% Leet ####\n",
    "df_test_offen_75_per_annot = create_leet_augmenter_df(\n",
    "    df_ori=df_test_offen, frac=0.75, augmenter=augmenter, column_to_leet=\"tweet\"\n",
    ")\n",
    "\n",
    "\n",
    "# Assuming df has the columns 'leet_text', 'annotations', and 'Camouflaged'\n",
    "df_test_offen_75_per_annot[\"leet_mask_filter\"] = (\n",
    "    df_test_offen_75_per_annot.progress_apply(\n",
    "        lambda row: (\n",
    "            apply_masks(row[\"leet_text\"], extract_masking_indices(row[\"annotations\"]))\n",
    "            if row[\"Camouflaged\"]\n",
    "            else row[\"tweet\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "pd_2_spacy(\n",
    "    df_train=None,\n",
    "    df_dev=None,\n",
    "    df_test=df_test_offen_75_per_annot.loc[:, [\"leet_mask_filter\", \"test_label\"]],\n",
    "    train_output_path=None,\n",
    "    dev_output_path=None,\n",
    "    test_output_path=f\"{home}/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/{resiliance_level}/75_per/test_mask_filter.spacy\",\n",
    "    lang=\"en\",\n",
    "    labels=df_test_offen_75_per_annot[\"test_label\"].to_list(),\n",
    ")\n",
    "\n",
    "\n",
    "df_test_offen_75_per_annot[\"leet_out_filter\"] = (\n",
    "    df_test_offen_75_per_annot.progress_apply(\n",
    "        lambda row: (\n",
    "            apply_masks(\n",
    "                row[\"leet_text\"], extract_masking_indices(row[\"annotations\"]), \"\"\n",
    "            )\n",
    "            if row[\"Camouflaged\"]\n",
    "            else row[\"tweet\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "pd_2_spacy(\n",
    "    df_train=None,\n",
    "    df_dev=None,\n",
    "    df_test=df_test_offen_75_per_annot.loc[:, [\"leet_out_filter\", \"test_label\"]],\n",
    "    train_output_path=None,\n",
    "    dev_output_path=None,\n",
    "    test_output_path=f\"{home}/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/{resiliance_level}/75_per/test_out_filter.spacy\",\n",
    "    lang=\"en\",\n",
    "    labels=df_test_offen_75_per_annot[\"test_label\"].to_list(),\n",
    ")\n",
    "\n",
    "\n",
    "#### 100% Leet ####\n",
    "df_test_offen_100_per_annot = create_leet_augmenter_df(\n",
    "    df_ori=df_test_offen, frac=1, augmenter=augmenter, column_to_leet=\"tweet\"\n",
    ")\n",
    "\n",
    "\n",
    "# Assuming df has the columns 'leet_text', 'annotations', and 'Camouflaged'\n",
    "df_test_offen_100_per_annot[\"leet_mask_filter\"] = (\n",
    "    df_test_offen_100_per_annot.progress_apply(\n",
    "        lambda row: (\n",
    "            apply_masks(row[\"leet_text\"], extract_masking_indices(row[\"annotations\"]))\n",
    "            if row[\"Camouflaged\"]\n",
    "            else row[\"tweet\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "pd_2_spacy(\n",
    "    df_train=None,\n",
    "    df_dev=None,\n",
    "    df_test=df_test_offen_100_per_annot.loc[:, [\"leet_mask_filter\", \"test_label\"]],\n",
    "    train_output_path=None,\n",
    "    dev_output_path=None,\n",
    "    test_output_path=f\"{home}/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/{resiliance_level}/100_per/test_mask_filter.spacy\",\n",
    "    lang=\"en\",\n",
    "    labels=df_test_offen_100_per_annot[\"test_label\"].to_list(),\n",
    ")\n",
    "\n",
    "\n",
    "df_test_offen_100_per_annot[\"leet_out_filter\"] = (\n",
    "    df_test_offen_100_per_annot.progress_apply(\n",
    "        lambda row: (\n",
    "            apply_masks(\n",
    "                row[\"leet_text\"], extract_masking_indices(row[\"annotations\"]), \"\"\n",
    "            )\n",
    "            if row[\"Camouflaged\"]\n",
    "            else row[\"tweet\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "pd_2_spacy(\n",
    "    df_train=None,\n",
    "    df_dev=None,\n",
    "    df_test=df_test_offen_100_per_annot.loc[:, [\"leet_out_filter\", \"test_label\"]],\n",
    "    train_output_path=None,\n",
    "    dev_output_path=None,\n",
    "    test_output_path=f\"{home}/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/{resiliance_level}/100_per/test_out_filter.spacy\",\n",
    "    lang=\"en\",\n",
    "    labels=df_test_offen_100_per_annot[\"test_label\"].to_list(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Level X.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resiliance_level = \"Level_1.2\"\n",
    "resiliance_easy = [\"basic_leetspeak\"]\n",
    "augmenter = WordCamouflage_Augmenter.augmenter(\n",
    "        extractor_type=\"yake\",\n",
    "        max_top_n=20,\n",
    "        leet_punt_prb=0.9,\n",
    "        leet_change_prb=0.8,\n",
    "        leet_change_frq=0.8,\n",
    "        leet_uniform_change=0.5,\n",
    "        method=resiliance_easy,\n",
    "        return_kws = True\n",
    ")\n",
    "\n",
    "#### 10% Leet ####\n",
    "df_test_offen_10_per_annot = create_leet_augmenter_df(\n",
    "    df_ori=df_test_offen, frac=0.1, augmenter=augmenter, column_to_leet=\"tweet\"\n",
    ")\n",
    "\n",
    "\n",
    "# Assuming df has the columns 'leet_text', 'annotations', and 'Camouflaged'\n",
    "df_test_offen_10_per_annot[\"leet_mask_filter\"] = (\n",
    "    df_test_offen_10_per_annot.progress_apply(\n",
    "        lambda row: (\n",
    "            apply_masks(row[\"leet_text\"], extract_masking_indices(row[\"annotations\"]))\n",
    "            if row[\"Camouflaged\"]\n",
    "            else row[\"tweet\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "pd_2_spacy(\n",
    "    df_train=None,\n",
    "    df_dev=None,\n",
    "    df_test=df_test_offen_10_per_annot.loc[:, [\"leet_mask_filter\", \"test_label\"]],\n",
    "    train_output_path=None,\n",
    "    dev_output_path=None,\n",
    "    test_output_path=f\"{home}/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/{resiliance_level}/10_per/test_mask_filter.spacy\",\n",
    "    lang=\"en\",\n",
    "    labels=df_test_offen_10_per_annot[\"test_label\"].to_list(),\n",
    ")\n",
    "\n",
    "\n",
    "df_test_offen_10_per_annot[\"leet_out_filter\"] = (\n",
    "    df_test_offen_10_per_annot.progress_apply(\n",
    "        lambda row: (\n",
    "            apply_masks(\n",
    "                row[\"leet_text\"], extract_masking_indices(row[\"annotations\"]), \"\"\n",
    "            )\n",
    "            if row[\"Camouflaged\"]\n",
    "            else row[\"tweet\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "pd_2_spacy(\n",
    "    df_train=None,\n",
    "    df_dev=None,\n",
    "    df_test=df_test_offen_10_per_annot.loc[:, [\"leet_out_filter\", \"test_label\"]],\n",
    "    train_output_path=None,\n",
    "    dev_output_path=None,\n",
    "    test_output_path=f\"{home}/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/{resiliance_level}/10_per/test_out_filter.spacy\",\n",
    "    lang=\"en\",\n",
    "    labels=df_test_offen_10_per_annot[\"test_label\"].to_list(),\n",
    ")\n",
    "\n",
    "\n",
    "#### 25% Leet ####\n",
    "df_test_offen_25_per_annot = create_leet_augmenter_df(\n",
    "    df_ori=df_test_offen, frac=0.25, augmenter=augmenter, column_to_leet=\"tweet\"\n",
    ")\n",
    "\n",
    "\n",
    "# Assuming df has the columns 'leet_text', 'annotations', and 'Camouflaged'\n",
    "df_test_offen_25_per_annot[\"leet_mask_filter\"] = (\n",
    "    df_test_offen_25_per_annot.progress_apply(\n",
    "        lambda row: (\n",
    "            apply_masks(row[\"leet_text\"], extract_masking_indices(row[\"annotations\"]))\n",
    "            if row[\"Camouflaged\"]\n",
    "            else row[\"tweet\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "pd_2_spacy(\n",
    "    df_train=None,\n",
    "    df_dev=None,\n",
    "    df_test=df_test_offen_25_per_annot.loc[:, [\"leet_mask_filter\", \"test_label\"]],\n",
    "    train_output_path=None,\n",
    "    dev_output_path=None,\n",
    "    test_output_path=f\"{home}/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/{resiliance_level}/25_per/test_mask_filter.spacy\",\n",
    "    lang=\"en\",\n",
    "    labels=df_test_offen_25_per_annot[\"test_label\"].to_list(),\n",
    ")\n",
    "\n",
    "\n",
    "df_test_offen_25_per_annot[\"leet_out_filter\"] = (\n",
    "    df_test_offen_25_per_annot.progress_apply(\n",
    "        lambda row: (\n",
    "            apply_masks(\n",
    "                row[\"leet_text\"], extract_masking_indices(row[\"annotations\"]), \"\"\n",
    "            )\n",
    "            if row[\"Camouflaged\"]\n",
    "            else row[\"tweet\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "pd_2_spacy(\n",
    "    df_train=None,\n",
    "    df_dev=None,\n",
    "    df_test=df_test_offen_25_per_annot.loc[:, [\"leet_out_filter\", \"test_label\"]],\n",
    "    train_output_path=None,\n",
    "    dev_output_path=None,\n",
    "    test_output_path=f\"{home}/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/{resiliance_level}/25_per/test_out_filter.spacy\",\n",
    "    lang=\"en\",\n",
    "    labels=df_test_offen_25_per_annot[\"test_label\"].to_list(),\n",
    ")\n",
    "\n",
    "\n",
    "#### 50% Leet ####\n",
    "df_test_offen_50_per_annot = create_leet_augmenter_df(\n",
    "    df_ori=df_test_offen, frac=0.50, augmenter=augmenter, column_to_leet=\"tweet\"\n",
    ")\n",
    "\n",
    "\n",
    "# Assuming df has the columns 'leet_text', 'annotations', and 'Camouflaged'\n",
    "df_test_offen_50_per_annot[\"leet_mask_filter\"] = (\n",
    "    df_test_offen_50_per_annot.progress_apply(\n",
    "        lambda row: (\n",
    "            apply_masks(row[\"leet_text\"], extract_masking_indices(row[\"annotations\"]))\n",
    "            if row[\"Camouflaged\"]\n",
    "            else row[\"tweet\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "pd_2_spacy(\n",
    "    df_train=None,\n",
    "    df_dev=None,\n",
    "    df_test=df_test_offen_50_per_annot.loc[:, [\"leet_mask_filter\", \"test_label\"]],\n",
    "    train_output_path=None,\n",
    "    dev_output_path=None,\n",
    "    test_output_path=f\"{home}/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/{resiliance_level}/50_per/test_mask_filter.spacy\",\n",
    "    lang=\"en\",\n",
    "    labels=df_test_offen_50_per_annot[\"test_label\"].to_list(),\n",
    ")\n",
    "\n",
    "\n",
    "df_test_offen_50_per_annot[\"leet_out_filter\"] = (\n",
    "    df_test_offen_50_per_annot.progress_apply(\n",
    "        lambda row: (\n",
    "            apply_masks(\n",
    "                row[\"leet_text\"], extract_masking_indices(row[\"annotations\"]), \"\"\n",
    "            )\n",
    "            if row[\"Camouflaged\"]\n",
    "            else row[\"tweet\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "pd_2_spacy(\n",
    "    df_train=None,\n",
    "    df_dev=None,\n",
    "    df_test=df_test_offen_50_per_annot.loc[:, [\"leet_out_filter\", \"test_label\"]],\n",
    "    train_output_path=None,\n",
    "    dev_output_path=None,\n",
    "    test_output_path=f\"{home}/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/{resiliance_level}/50_per/test_out_filter.spacy\",\n",
    "    lang=\"en\",\n",
    "    labels=df_test_offen_50_per_annot[\"test_label\"].to_list(),\n",
    ")\n",
    "\n",
    "\n",
    "#### 75% Leet ####\n",
    "df_test_offen_75_per_annot = create_leet_augmenter_df(\n",
    "    df_ori=df_test_offen, frac=0.75, augmenter=augmenter, column_to_leet=\"tweet\"\n",
    ")\n",
    "\n",
    "\n",
    "# Assuming df has the columns 'leet_text', 'annotations', and 'Camouflaged'\n",
    "df_test_offen_75_per_annot[\"leet_mask_filter\"] = (\n",
    "    df_test_offen_75_per_annot.progress_apply(\n",
    "        lambda row: (\n",
    "            apply_masks(row[\"leet_text\"], extract_masking_indices(row[\"annotations\"]))\n",
    "            if row[\"Camouflaged\"]\n",
    "            else row[\"tweet\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "pd_2_spacy(\n",
    "    df_train=None,\n",
    "    df_dev=None,\n",
    "    df_test=df_test_offen_75_per_annot.loc[:, [\"leet_mask_filter\", \"test_label\"]],\n",
    "    train_output_path=None,\n",
    "    dev_output_path=None,\n",
    "    test_output_path=f\"{home}/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/{resiliance_level}/75_per/test_mask_filter.spacy\",\n",
    "    lang=\"en\",\n",
    "    labels=df_test_offen_75_per_annot[\"test_label\"].to_list(),\n",
    ")\n",
    "\n",
    "\n",
    "df_test_offen_75_per_annot[\"leet_out_filter\"] = (\n",
    "    df_test_offen_75_per_annot.progress_apply(\n",
    "        lambda row: (\n",
    "            apply_masks(\n",
    "                row[\"leet_text\"], extract_masking_indices(row[\"annotations\"]), \"\"\n",
    "            )\n",
    "            if row[\"Camouflaged\"]\n",
    "            else row[\"tweet\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "pd_2_spacy(\n",
    "    df_train=None,\n",
    "    df_dev=None,\n",
    "    df_test=df_test_offen_75_per_annot.loc[:, [\"leet_out_filter\", \"test_label\"]],\n",
    "    train_output_path=None,\n",
    "    dev_output_path=None,\n",
    "    test_output_path=f\"{home}/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/{resiliance_level}/75_per/test_out_filter.spacy\",\n",
    "    lang=\"en\",\n",
    "    labels=df_test_offen_75_per_annot[\"test_label\"].to_list(),\n",
    ")\n",
    "\n",
    "\n",
    "#### 100% Leet ####\n",
    "df_test_offen_100_per_annot = create_leet_augmenter_df(\n",
    "    df_ori=df_test_offen, frac=1, augmenter=augmenter, column_to_leet=\"tweet\"\n",
    ")\n",
    "\n",
    "\n",
    "# Assuming df has the columns 'leet_text', 'annotations', and 'Camouflaged'\n",
    "df_test_offen_100_per_annot[\"leet_mask_filter\"] = (\n",
    "    df_test_offen_100_per_annot.progress_apply(\n",
    "        lambda row: (\n",
    "            apply_masks(row[\"leet_text\"], extract_masking_indices(row[\"annotations\"]))\n",
    "            if row[\"Camouflaged\"]\n",
    "            else row[\"tweet\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "pd_2_spacy(\n",
    "    df_train=None,\n",
    "    df_dev=None,\n",
    "    df_test=df_test_offen_100_per_annot.loc[:, [\"leet_mask_filter\", \"test_label\"]],\n",
    "    train_output_path=None,\n",
    "    dev_output_path=None,\n",
    "    test_output_path=f\"{home}/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/{resiliance_level}/100_per/test_mask_filter.spacy\",\n",
    "    lang=\"en\",\n",
    "    labels=df_test_offen_100_per_annot[\"test_label\"].to_list(),\n",
    ")\n",
    "\n",
    "\n",
    "df_test_offen_100_per_annot[\"leet_out_filter\"] = (\n",
    "    df_test_offen_100_per_annot.progress_apply(\n",
    "        lambda row: (\n",
    "            apply_masks(\n",
    "                row[\"leet_text\"], extract_masking_indices(row[\"annotations\"]), \"\"\n",
    "            )\n",
    "            if row[\"Camouflaged\"]\n",
    "            else row[\"tweet\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "pd_2_spacy(\n",
    "    df_train=None,\n",
    "    df_dev=None,\n",
    "    df_test=df_test_offen_100_per_annot.loc[:, [\"leet_out_filter\", \"test_label\"]],\n",
    "    train_output_path=None,\n",
    "    dev_output_path=None,\n",
    "    test_output_path=f\"{home}/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/{resiliance_level}/100_per/test_out_filter.spacy\",\n",
    "    lang=\"en\",\n",
    "    labels=df_test_offen_100_per_annot[\"test_label\"].to_list(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load spacy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "\n",
    "offen_10_leet_data_path = \"/home/alvaro/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/Level_1.1/100_per/test_mask_filter.spacy\"\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Cargar los datos\n",
    "doc_bin = DocBin().from_disk(offen_10_leet_data_path)\n",
    "docs = list(doc_bin.get_docs(nlp.vocab))\n",
    "\n",
    "# Convertir a DataFrame \n",
    "#  doc.cats --> {'OFF': False, 'NOT': True}\n",
    "data = [{\n",
    "    'text': doc.text,\n",
    "    'test_label': next((label for label, is_true in doc.cats.items() if is_true), None)\n",
    "} for doc in docs]\n",
    "offen_10_leet_mask_filter_df_v1 = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "\n",
    "offen_10_leet_data_path = \"/home/alvaro/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/Level_1.2/100_per/test_mask_filter.spacy\"\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Cargar los datos\n",
    "doc_bin = DocBin().from_disk(offen_10_leet_data_path)\n",
    "docs = list(doc_bin.get_docs(nlp.vocab))\n",
    "\n",
    "# Convertir a DataFrame \n",
    "#  doc.cats --> {'OFF': False, 'NOT': True}\n",
    "data = [{\n",
    "    'text': doc.text,\n",
    "    'test_label': next((label for label, is_true in doc.cats.items() if is_true), None)\n",
    "} for doc in docs]\n",
    "offen_10_leet_mask_filter_df_v2 = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "\n",
    "offen_10_leet_data_path = \"/home/alvaro/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/Level_3.2/100_per/test_mask_filter.spacy\"\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "# Cargar los datos\n",
    "doc_bin = DocBin().from_disk(offen_10_leet_data_path)\n",
    "docs = list(doc_bin.get_docs(nlp.vocab))\n",
    "\n",
    "# Convertir a DataFrame \n",
    "#  doc.cats --> {'OFF': False, 'NOT': True}\n",
    "data = [{\n",
    "    'text': doc.text,\n",
    "    'test_label': next((label for label, is_true in doc.cats.items() if is_true), None)\n",
    "} for doc in docs]\n",
    "offen_10_leet_mask_filter_df_3v2 = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>test_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#[MASK]. Don't [MASK] all of your [MASK]. If you are not saving [MASK] 15%  of what you earn,  [MASK] today.  Look at your income and expenses, find out where you can [MASK] to cut back and get 15% you save.</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[MASK] @[MASK] follows me!</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                              text  \\\n",
       "0  #[MASK]. Don't [MASK] all of your [MASK]. If you are not saving [MASK] 15%  of what you earn,  [MASK] today.  Look at your income and expenses, find out where you can [MASK] to cut back and get 15% you save.   \n",
       "1                                                                                                                                                                                       [MASK] @[MASK] follows me!   \n",
       "\n",
       "  test_label  \n",
       "0        NOT  \n",
       "1        NOT  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>test_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#[MASK]. Don't [MASK] all of your [MASK]. If you are not [MASK] [MASK] 15%  of what you [MASK],  [MASK] [MASK].  Look at your [MASK] and [MASK], [MASK] out where you can [MASK] to [MASK] [MASK] and get 15% you [MASK].</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[MASK] @[MASK] follows me!</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                        text  \\\n",
       "0  #[MASK]. Don't [MASK] all of your [MASK]. If you are not [MASK] [MASK] 15%  of what you [MASK],  [MASK] [MASK].  Look at your [MASK] and [MASK], [MASK] out where you can [MASK] to [MASK] [MASK] and get 15% you [MASK].   \n",
       "1                                                                                                                                                                                                 [MASK] @[MASK] follows me!   \n",
       "\n",
       "  test_label  \n",
       "0        NOT  \n",
       "1        NOT  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>test_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#[MASK]. Don't [MASK] all of your [MASK]. If you are not [MASK] [MASK] 15%  of what you [MASK],  [MASK] [MASK].  Look at your [MASK] and [MASK], [MASK] out where you can [MASK] to [MASK] [MASK] and get 15% you [MASK].</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[MASK] @[MASK] follows me!</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                        text  \\\n",
       "0  #[MASK]. Don't [MASK] all of your [MASK]. If you are not [MASK] [MASK] 15%  of what you [MASK],  [MASK] [MASK].  Look at your [MASK] and [MASK], [MASK] out where you can [MASK] to [MASK] [MASK] and get 15% you [MASK].   \n",
       "1                                                                                                                                                                                                 [MASK] @[MASK] follows me!   \n",
       "\n",
       "  test_label  \n",
       "0        NOT  \n",
       "1        NOT  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "display(offen_10_leet_mask_filter_df_v1.head(2))\n",
    "display(offen_10_leet_mask_filter_df_v2.head(2))\n",
    "display(offen_10_leet_mask_filter_df_3v2.head(2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>test_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#[MASK]. Don't [MASK] all of your [MASK]. If you are not [MASK] [MASK] 15%  of what you [MASK],  [MASK] [MASK].  Look at your [MASK] and [MASK], [MASK] out where you can [MASK] to [MASK] [MASK] and get 15% you [MASK].</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[MASK] @[MASK] follows me!</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@[MASK] @[MASK] @[MASK] I'm [MASK] by the way and I [MASK] the [MASK] [MASK] already in [MASK] if it means [MASK] like you don't ever [MASK] a [MASK] you are saying has nothing to do with this.</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@[MASK] [MASK] considers [MASK] the [MASK] [MASK] and having [MASK] later in the [MASK] [MASK] she is a [MASK] [MASK]</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#[MASK] #[MASK]☠️#[MASK] #[MASK] #[MASK] #[MASK] #[MASK]  '... in an [MASK] where [MASK] [MASK] [MASK] [MASK] on all the [MASK] that [MASK] to them most — [MASK], [MASK] [MASK], [MASK] [MASK] and so on — [MASK] ... on the [MASK] [MASK]....'[MASK]</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>#[MASK]: If you [MASK] in #[MASK], [MASK] wants to [MASK] your [MASK] on the [MASK] of a new [MASK] [MASK] [MASK]. She is [MASK] to [MASK] a new [MASK] [MASK] [MASK] in the [MASK] [MASK] [MASK] [MASK] [MASK] on [MASK] [MASK]. What do you think?  [MASK] [MASK]</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>[MASK] [MASK] [MASK] #[MASK]   [MASK]</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>#[MASK] I saw the [MASK] [MASK] , thank you for [MASK] us so much , just the way we [MASK] you [MASK] , you are [MASK] with [MASK] ♥️♥️</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>#[MASK]: [MASK], 13, [MASK], [MASK] and [MASK] From [MASK] Over —[MASK] for it— #[MASK] [MASK] from [MASK] [MASK]   [MASK] #[MASK] #[MASK] #[MASK] #[MASK] #[MASK] #[MASK] #[MASK]</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>#[MASK] [MASK] [MASK] #[MASK] ! [MASK] does she think she is, a [MASK]? [MASK] [MASK] [MASK]</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>860 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                    text  \\\n",
       "0                                              #[MASK]. Don't [MASK] all of your [MASK]. If you are not [MASK] [MASK] 15%  of what you [MASK],  [MASK] [MASK].  Look at your [MASK] and [MASK], [MASK] out where you can [MASK] to [MASK] [MASK] and get 15% you [MASK].   \n",
       "1                                                                                                                                                                                                                                             [MASK] @[MASK] follows me!   \n",
       "2                                                                      @[MASK] @[MASK] @[MASK] I'm [MASK] by the way and I [MASK] the [MASK] [MASK] already in [MASK] if it means [MASK] like you don't ever [MASK] a [MASK] you are saying has nothing to do with this.   \n",
       "3                                                                                                                                                  @[MASK] [MASK] considers [MASK] the [MASK] [MASK] and having [MASK] later in the [MASK] [MASK] she is a [MASK] [MASK]   \n",
       "4                 #[MASK] #[MASK]☠️#[MASK] #[MASK] #[MASK] #[MASK] #[MASK]  '... in an [MASK] where [MASK] [MASK] [MASK] [MASK] on all the [MASK] that [MASK] to them most — [MASK], [MASK] [MASK], [MASK] [MASK] and so on — [MASK] ... on the [MASK] [MASK]....'[MASK]   \n",
       "..                                                                                                                                                                                                                                                                   ...   \n",
       "855  #[MASK]: If you [MASK] in #[MASK], [MASK] wants to [MASK] your [MASK] on the [MASK] of a new [MASK] [MASK] [MASK]. She is [MASK] to [MASK] a new [MASK] [MASK] [MASK] in the [MASK] [MASK] [MASK] [MASK] [MASK] on [MASK] [MASK]. What do you think?  [MASK] [MASK]   \n",
       "856                                                                                                                                                                                                                                [MASK] [MASK] [MASK] #[MASK]   [MASK]   \n",
       "857                                                                                                                              #[MASK] I saw the [MASK] [MASK] , thank you for [MASK] us so much , just the way we [MASK] you [MASK] , you are [MASK] with [MASK] ♥️♥️   \n",
       "858                                                                                   #[MASK]: [MASK], 13, [MASK], [MASK] and [MASK] From [MASK] Over —[MASK] for it— #[MASK] [MASK] from [MASK] [MASK]   [MASK] #[MASK] #[MASK] #[MASK] #[MASK] #[MASK] #[MASK] #[MASK]   \n",
       "859                                                                                                                                                                         #[MASK] [MASK] [MASK] #[MASK] ! [MASK] does she think she is, a [MASK]? [MASK] [MASK] [MASK]   \n",
       "\n",
       "    test_label  \n",
       "0          NOT  \n",
       "1          NOT  \n",
       "2          NOT  \n",
       "3          NOT  \n",
       "4          NOT  \n",
       "..         ...  \n",
       "855        NOT  \n",
       "856        NOT  \n",
       "857        NOT  \n",
       "858        NOT  \n",
       "859        OFF  \n",
       "\n",
       "[860 rows x 2 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offen_10_leet_mask_filter_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLI command to evaluate the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "    python -m spacy evaluate path_model data_path_test_mask_filter.spacy  --gpu-id 0 --output output_path_test_mask_filter_result_25.json\n",
    "```\n",
    "\n",
    "For example\n",
    "\n",
    "```bash\n",
    "    python -m spacy evaluate /home/alvaro/work/WordCamouflage_Resiliance/code/models/bert-base-uncased_naive/model-best /home/alvaro/work/WordCamouflage_Resiliance/code/Spacy_Data/Offen_SemEval_2019/Leet_Data/Level_1.1/25_per/test_mask_filter.spacy  --gpu-id 0 --output /home/alvaro/work/WordCamouflage_Resiliance/code/models/bert-base-uncased_naive/model-best/Filter_mask/test_mask_filter_result_25.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the results in the output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blank\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cats_macro_f</th>\n",
       "      <td>0.742304</td>\n",
       "      <td>0.727541</td>\n",
       "      <td>0.719691</td>\n",
       "      <td>0.701188</td>\n",
       "      <td>0.691769</td>\n",
       "      <td>0.641577</td>\n",
       "      <td>0.668116</td>\n",
       "      <td>0.565613</td>\n",
       "      <td>0.640255</td>\n",
       "      <td>0.439124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0         1         2         3         4         5  \\\n",
       "cats_macro_f  0.742304  0.727541  0.719691  0.701188  0.691769  0.641577   \n",
       "\n",
       "                     6         7         8         9  \n",
       "cats_macro_f  0.668116  0.565613  0.640255  0.439124  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to data frame\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "filter = \"blank\"\n",
    "directory = f\"/home/alvaro/work/WordCamouflage_Resiliance/code/models/mbart-50-naive/model-best/Filter_{filter}\"\n",
    "\n",
    "\n",
    "# Lista de nombres de archivos en el orden deseado\n",
    "file_order = [\n",
    "    f\"test_{filter}_filter_result_10_v1.json\",\n",
    "    f\"test_{filter}_filter_result_10_v2.json\",\n",
    "    f\"test_{filter}_filter_result_25_v1.json\",\n",
    "    f\"test_{filter}_filter_result_25_v2.json\",\n",
    "    f\"test_{filter}_filter_result_50_v1.json\",\n",
    "    f\"test_{filter}_filter_result_50_v2.json\",\n",
    "    f\"test_{filter}_filter_result_75_v1.json\",\n",
    "    f\"test_{filter}_filter_result_75_v2.json\",\n",
    "    f\"test_{filter}_filter_result_100_v1.json\",\n",
    "    f\"test_{filter}_filter_result_100_v2.json\",\n",
    "]\n",
    "\n",
    "results = []\n",
    "for filename in file_order:\n",
    "    with open(os.path.join(directory, filename), 'r') as f:\n",
    "        data = json.load(f)\n",
    "        results.append(data)\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.loc[:, \"cats_macro_f\"]  # rotate\n",
    "# rotate\n",
    "print(filter)\n",
    "df_results.loc[:, \"cats_macro_f\"].to_frame().T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WordCamouflage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
